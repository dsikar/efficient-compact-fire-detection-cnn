This firedetectionpytorch-readme.txt file was generated on 20210118 by Neelanjan Bhowmik.

-------------------
GENERAL INFORMATION
-------------------

Title of Dataset: Pretrained Neural Network Models and test video for Thomson 2020 study - PyTorch format

Author Information (Name, Institution, Address, Email)

	Principal Investigator: William Thomson, Durham University, UK, william.g.thomson@durham.ac.uk
	Associate or Co-investigator: Neelanjan Bhowmik, Durham University, UK, neelanjan.bhowmik@durham.ac,uk
	Alternate Contact(s): Toby P. Breckon, Durham University, UK, toby.breckon@durham.ac.uk 

Date of data collection (single date, range, approximate date): Jan, 2021

Geographic location of data collection: Durham University, Durham, UK

Information about funding sources or sponsorship that supported the collection of the data: Durham University, UK


--------------------------
SHARING/ACCESS INFORMATION
-------------------------- 

Licenses/restrictions placed on the data, or limitations of reuse: MIT Licence (MIT), Creative Commons Attribution 4.0 International (CC BY) 
 
Recommended citation for the data: Efficient and Compact Convolutional Neural Network Architectures for Non-temporal Real-time Fire Detection, W. Thomson, N. Bhowmik, T.P. Breckon), In Proc. Int. Conf. Machine Learning Applications, IEEE, 2020.

Citation for and links to publications that cite or use the data: To appear.

Links to other publicly accessible locations of the data:

Links/relationships to ancillary or related data sets: 


--------------------
DATA & FILE OVERVIEW
--------------------

File list (filenames, directory structure (for zipped files) and brief description of all data files): This file contains supporting materials in the form of the pre-trained network models used in the Fire detection study by Thomson, Bhowmik, and Breckon, 2020. It contains four pre-trained network models (two full frame and two superpixel files) and a test video file (.mp4 format).  

Relationship between files, if important for context:  

Additional related data collected that was not included in the current data package:

If data was derived from another source, list source:

If there are there multiple versions of the dataset, list the file updated, when and why update was made:


--------------------------
METHODOLOGICAL INFORMATION
--------------------------

Description of methods used for collection/generation of data: Efficient and Compact Convolutional Neural Network Architectures for Non-temporal Real-time Fire Detection, W. Thomson, N. Bhowmik, T.P. Breckon), In Proc. Int. Conf. Machine Learning Applications, IEEE, 2020.

Methods for processing the data: 

Software- or Instrument-specific information needed to interpret the data, including software and hardware version numbers: Python >=3.6, PyTorch >=1.5

Standards and calibration information, if appropriate:

Environmental/experimental conditions:

Describe any quality-assurance procedures performed on the data:

People involved with sample collection, processing, analysis and/or submission:


--------------------------
DATA-SPECIFIC INFORMATION 
--------------------------

Number of variables:

Number of cases/rows: 

Variable list, defining any abbreviations, units of measure, codes or symbols used:
   
Missing data codes:

Specialized formats or other abbreviations used: